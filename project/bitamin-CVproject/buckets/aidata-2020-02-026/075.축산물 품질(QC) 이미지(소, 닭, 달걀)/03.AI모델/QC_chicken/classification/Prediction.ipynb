{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\r\n",
      "CPU op-mode(s):                  32-bit, 64-bit\r\n",
      "Byte Order:                      Little Endian\r\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\r\n",
      "CPU(s):                          64\r\n",
      "On-line CPU(s) list:             0-63\r\n",
      "Thread(s) per core:              2\r\n",
      "Core(s) per socket:              16\r\n",
      "Socket(s):                       2\r\n",
      "NUMA node(s):                    2\r\n",
      "Vendor ID:                       GenuineIntel\r\n",
      "CPU family:                      6\r\n",
      "Model:                           85\r\n",
      "Model name:                      Intel(R) Xeon(R) Platinum 8153 CPU @ 2.00GHz\r\n",
      "Stepping:                        4\r\n",
      "CPU MHz:                         2204.039\r\n",
      "CPU max MHz:                     2800.0000\r\n",
      "CPU min MHz:                     1000.0000\r\n",
      "BogoMIPS:                        4000.00\r\n",
      "Virtualization:                  VT-x\r\n",
      "L1d cache:                       1 MiB\r\n",
      "L1i cache:                       1 MiB\r\n",
      "L2 cache:                        32 MiB\r\n",
      "L3 cache:                        44 MiB\r\n",
      "NUMA node0 CPU(s):               0-15,32-47\r\n",
      "NUMA node1 CPU(s):               16-31,48-63\r\n",
      "Vulnerability Itlb multihit:     KVM: Vulnerable\r\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\r\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT vulnerable\r\n",
      "Vulnerability Meltdown:          Mitigation; PTI\r\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\r\n",
      "                                 ia prctl and seccomp\r\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\r\n",
      "                                  pointer sanitization\r\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, IBPB condit\r\n",
      "                                 ional, IBRS_FW, STIBP conditional, RSB filling\r\n",
      "Vulnerability Srbds:             Not affected\r\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT vulnerable\r\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\r\n",
      "                                 r pge mca cmov pat pse36 clflush dts acpi mmx f\r\n",
      "                                 xsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rd\r\n",
      "                                 tscp lm constant_tsc art arch_perfmon pebs bts \r\n",
      "                                 rep_good nopl xtopology nonstop_tsc cpuid aperf\r\n",
      "                                 mperf pni pclmulqdq dtes64 monitor ds_cpl vmx s\r\n",
      "                                 mx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid d\r\n",
      "                                 ca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadli\r\n",
      "                                 ne_timer aes xsave avx f16c rdrand lahf_lm abm \r\n",
      "                                 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 inv\r\n",
      "                                 pcid_single pti intel_ppin ssbd mba ibrs ibpb s\r\n",
      "                                 tibp tpr_shadow vnmi flexpriority ept vpid ept_\r\n",
      "                                 ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 \r\n",
      "                                 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq\r\n",
      "                                  rdseed adx smap clflushopt clwb intel_pt avx51\r\n",
      "                                 2cd avx512bw avx512vl xsaveopt xsavec xgetbv1 x\r\n",
      "                                 saves cqm_llc cqm_occup_llc cqm_mbm_total cqm_m\r\n",
      "                                 bm_local dtherm ida arat pln pts hwp hwp_act_wi\r\n",
      "                                 ndow hwp_pkg_req pku ospke md_clear flush_l1d\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 17 07:43:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:37:00.0 Off |                    0 |\n",
      "| N/A   74C    P0    34W /  70W |   3259MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   39C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1315582      C   ...test/anaconda3/bin/python     1943MiB |\n",
      "|    0   N/A  N/A   1315686      C   ...da3/envs/torch/bin/python     1313MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAM 용량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          125Gi       9.3Gi       1.6Gi        50Mi       114Gi       115Gi\r\n",
      "Swap:         8.0Gi        86Mi       7.9Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDD 용량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "udev             63G     0   63G   0% /dev\r\n",
      "tmpfs            13G  2.7M   13G   1% /run\r\n",
      "/dev/sda2       549G  418G  104G  81% /\r\n",
      "tmpfs            63G   12K   63G   1% /dev/shm\r\n",
      "tmpfs           5.0M     0  5.0M   0% /run/lock\r\n",
      "tmpfs            63G     0   63G   0% /sys/fs/cgroup\r\n",
      "/dev/sda1       511M  7.8M  504M   2% /boot/efi\r\n",
      "/dev/loop4       56M   56M     0 100% /snap/core18/1944\r\n",
      "tmpfs            13G     0   13G   0% /run/user/1000\r\n",
      "/dev/loop6       32M   32M     0 100% /snap/snapd/10707\r\n",
      "/dev/loop0       70M   70M     0 100% /snap/lxd/19032\r\n",
      "/dev/loop1       70M   70M     0 100% /snap/lxd/19188\r\n",
      "/dev/sdb2       466G  240G  226G  52% /home/test/mount_folder\r\n",
      "/dev/loop5       56M   56M     0 100% /snap/core18/1988\r\n",
      "/dev/loop2       32M   32M     0 100% /snap/snapd/11036\r\n"
     ]
    }
   ],
   "source": [
    "# 디스크 용량 확인\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OS 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Ubuntu\"\r\n",
      "VERSION=\"20.04.1 LTS (Focal Fossa)\"\r\n",
      "ID=ubuntu\r\n",
      "ID_LIKE=debian\r\n",
      "PRETTY_NAME=\"Ubuntu 20.04.1 LTS\"\r\n",
      "VERSION_ID=\"20.04\"\r\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\r\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\r\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\r\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\r\n",
      "VERSION_CODENAME=focal\r\n",
      "UBUNTU_CODENAME=focal\r\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import explain\n",
    "import chicken_dataset as Dataset\n",
    "import Utility_invert as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.7.0 (default, Oct  9 2018, 10:31:47) \n",
      "[GCC 7.3.0]\n",
      "pandas version: 1.1.5\n",
      "numpy version: 1.19.2\n",
      "sklearn version: 0.23.2\n",
      "torch version: 1.7.1\n",
      "albumentations version: 0.5.2\n"
     ]
    }
   ],
   "source": [
    "print('python version:',sys.version)\n",
    "print('pandas version:',pd.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "\n",
    "print('sklearn version:', sklearn.__version__)\n",
    "print('torch version:', torch.__version__)\n",
    "#print('torchvision version:', torchvision.__version__)\n",
    "print('albumentations version:', A.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 파라미터 (Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 입력할 Input 이미지의 크기를 지정함.\n",
    "IMG_WIDTH = 448\n",
    "IMG_HEIGHT = 448\n",
    "\n",
    "# 배치 사이즈 임의 지정\n",
    "batch_size = 4\n",
    "\n",
    "# 데이터를 읽어올 경로를 지정함.\n",
    "data_dir='../Dataset/preprocessed/classification'\n",
    "# 학습된 모델이 저장된 경로를 지정함.\n",
    "ckpt_dir = \"./Models/\"\n",
    "\n",
    "# 모델 이름\n",
    "Model_name = \"chicken_classification\"\n",
    "# 모델을 연산할 장비 설정 (Docker환경에서 작동할 수 있도록 CPU에서 계산함)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test 데이터 셋 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abnormal의 경우, 총 85개 이미지가 있으며 train : valid : test = 55 : 15 : 15 비율을 따랐음. (Preprocess.ipynb 참고)<br>\n",
    "이를 바탕으로, valid, test set 안에서 Abnormal 이 10% 를 차지하도록 구성하였음.<br>\n",
    "(\"Deep Learning for Anomaly Detection: A Review\", 2020, Pang. G, Shen. C, et al. 의 Table 3 을 참고하여 10% 로 선정.)\n",
    "\n",
    "train set의 class 분포는 위와 같은 비율을 따르지 않고 Normal의 모든 이미지를 사용함.<br>\n",
    "또, 55개의 Abnormal 데이터를 20배 가량 단순 over-sampling 하여, 더 나은 모델 학습을 기대함."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "label=['Normal','Abnormal']\n",
    "\n",
    "for set_ in ['train','val','test']:\n",
    "    set_size=len(glob(osp.join(data_dir, set_, '*', '*.jpg'), recursive=True))\n",
    "    if set_=='val':\n",
    "        print(f\"{set_+'idation'} set size: {set_size}\\n\")\n",
    "    else:\n",
    "        print(f\"{set_} set size: {set_size}\\n\")\n",
    "    \n",
    "    for i in range(2):\n",
    "        size=len(glob(osp.join(data_dir, set_, str(i), '*.jpg'), recursive=True))\n",
    "        print(f\"The number of Class {label[i]}: {size} / {set_size} = {size/set_size :.2f}\")\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 셋 (Dataset) 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 transformation\n",
    "test_compose=A.Compose([\n",
    "    A.Resize(IMG_HEIGHT,IMG_WIDTH),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Test set을 읽어옴\n",
    "test_dataset=Dataset.ChickenDataset(os.path.join(data_dir, 'test'), transforms=test_compose)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=batch_size, pin_memory=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterions : 파계 분류 기준 설정에 필요한 metric\n",
    "criterions = {\n",
    "\"Reconstruction\": nn.MSELoss(reduction='none')\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기 (Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델 가중치를 불러옴\n",
    "checkpoint=torch.load(ckpt_dir + Model_name + '.pth', map_location=device)\n",
    "\n",
    "# model : Adversarial AutoEncoder\n",
    "models=U.Create_Models(base_model='RESNET50')\n",
    "\n",
    "models['Encoder'].load_state_dict(checkpoint['state_dict']['Encoder'])\n",
    "models['Decoder'].load_state_dict(checkpoint['state_dict']['Decoder'])\n",
    "threshold=checkpoint['val_best_f1_threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 전, ImageNet 데이터로 Pretrain 된 기본 모델 불러오기 (Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model : Adversarial AutoEncoder\n",
    "base_model=U.Create_Models(base_model='RESNET50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 확인 (Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Encoder': Encoder(\n",
       "   (model_ft): ResNet(\n",
       "     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     (layer1): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer2): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (3): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer3): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (3): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (4): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (5): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer4): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "     (fc): Identity()\n",
       "   )\n",
       "   (encoder_fc): Sequential(\n",
       "     (encoder_fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (encoder_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (encoder_activation1): ReLU(inplace=True)\n",
       "     (encoder_dropout1): Dropout(p=0.2, inplace=False)\n",
       "     (encoder_fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'Decoder': Decoder(\n",
       "   (decoder_fc): Sequential(\n",
       "     (decoder_fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "     (decoder_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (decoder_activation1): ReLU(inplace=True)\n",
       "     (decoder_dropout1): Dropout(p=0.2, inplace=False)\n",
       "     (decoder_fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "     (decoder_bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (decoder_activation2): ReLU(inplace=True)\n",
       "     (decoder_dropout2): Dropout(p=0.2, inplace=False)\n",
       "     (decoder_fc3): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'Discriminator': Discriminator(\n",
       "   (discriminator_fc): Sequential(\n",
       "     (discriminator_fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "     (discriminator_bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (discriminator_activation1): ReLU(inplace=True)\n",
       "     (discriminator_dropout1): Dropout(p=0.2, inplace=False)\n",
       "     (discriminator_fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "     (discriminator_activation4): Sigmoid()\n",
       "   )\n",
       " ),\n",
       " 'Z_dim': 128}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 (Test) 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ImageNet 데이터로 Pretrain 된 기본 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 이미지 평가 (Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 시작 시간 : 2021-02-17 16:44:00\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'테스트 시작 시간 : {nowDatetime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "since=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [01:41,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# 네트워크를 evaluation 용으로 선언\n",
    "for key in list(base_model.keys()):\n",
    "    if key != \"Z_dim\":\n",
    "        base_model[key]=base_model[key].eval().to(device)\n",
    "        \n",
    "# 모델 성능 확인을 위한 결과물 저장\n",
    "recon_dict={'recon_error':[], 'true_label_tot': []}\n",
    "\n",
    "# test 이기 때문에 backprop 진행 x\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in tqdm(enumerate(test_dataloader)):\n",
    "        \n",
    "        images=images.to(device)\n",
    "        target=target.to(device)\n",
    "\n",
    "        recon_dict['true_label_tot'].extend(list(target.numpy()))\n",
    "\n",
    "        x, z = base_model[\"Encoder\"](images)\n",
    "        x_recon = base_model[\"Decoder\"](z)\n",
    "        \n",
    "        reconstruction_loss = criterions[\"Reconstruction\"](x_recon, x).mean(dim=1)            \n",
    "        recon_dict['recon_error'].extend(reconstruction_loss.detach().cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "total_recon_loss, true_label_tot= recon_dict['recon_error'] , recon_dict['true_label_tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 소요 시간: 1m 41s\n"
     ]
    }
   ],
   "source": [
    "end=time.time()\n",
    "print(f'테스트 소요 시간: {int((end-since)//60)}m {int((end-since)%60)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 종료 시간 : 2021-02-17 16:45:42\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'테스트 종료 시간 : {nowDatetime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 생성\n",
    "prediction=explain.Prediction(total_recon_loss, true_label_tot, threshold)\n",
    "true_total_label, pred_total_label=prediction.get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Abnormal  All\n",
      "True                    \n",
      "Normal          135  135\n",
      "Abnormal         15   15\n",
      "All             150  150\n",
      "\n",
      "\n",
      "#-- Confusion Matrix for class Normal\n",
      "\n",
      "                      Pred       \n",
      "                Non Normal Normal\n",
      "True Non Normal         15      0\n",
      "     Normal            135      0\n",
      "F1-Score for class Normal : 0.000\n",
      "-----------------------------------\n",
      "\n",
      "#-- Confusion Matrix for class Abnormal\n",
      "\n",
      "                          Pred         \n",
      "                  Non Abnormal Abnormal\n",
      "True Non Abnormal            0      135\n",
      "     Abnormal                0       15\n",
      "F1-Score for class Abnormal : 0.182\n",
      "-----------------------------------\n",
      "\n",
      "#-- Final Macro F1-Score\n",
      "( 0.000 + 0.182 ) / 2 = 0.0909\n"
     ]
    }
   ],
   "source": [
    "result=explain.ShowResult(true_total_label, pred_total_label)\n",
    "result.show_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 기본 모델을 Fine Tuning (학습) 한 모델 성능 평가 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 이미지 평가 (Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 시작 시간 : 2021-02-17 16:45:43\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'테스트 시작 시간 : {nowDatetime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "since=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [01:46,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# 네트워크를 evaluation 용으로 선언\n",
    "for key in list(models.keys()):\n",
    "    if key != \"Z_dim\":\n",
    "        models[key]=models[key].eval().to(device)\n",
    "        \n",
    "# 모델 성능 확인을 위한 결과물 저장\n",
    "recon_dict={'recon_error':[], 'true_label_tot': []}\n",
    "\n",
    "# test 이기 때문에 backprop 진행 x\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in tqdm(enumerate(test_dataloader)):\n",
    "        \n",
    "        images=images.to(device)\n",
    "        target=target.to(device)\n",
    "\n",
    "        recon_dict['true_label_tot'].extend(list(target.numpy()))\n",
    "\n",
    "        x, z = models[\"Encoder\"](images)\n",
    "        x_recon = models[\"Decoder\"](z)\n",
    "        \n",
    "        reconstruction_loss = criterions[\"Reconstruction\"](x_recon, x).mean(dim=1)            \n",
    "        recon_dict['recon_error'].extend(reconstruction_loss.detach().cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "total_recon_loss, true_label_tot= recon_dict['recon_error'] , recon_dict['true_label_tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 소요 시간: 1m 46s\n"
     ]
    }
   ],
   "source": [
    "end=time.time()\n",
    "print(f'테스트 소요 시간: {int((end-since)//60)}m {int((end-since)%60)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 종료 시간 : 2021-02-17 16:47:29\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'테스트 종료 시간 : {nowDatetime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 생성\n",
    "prediction=explain.Prediction(total_recon_loss, true_label_tot, threshold)\n",
    "true_total_label, pred_total_label=prediction.get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Normal  Abnormal  All\n",
      "True                            \n",
      "Normal        131         4  135\n",
      "Abnormal        5        10   15\n",
      "All           136        14  150\n",
      "\n",
      "\n",
      "#-- Confusion Matrix for class Normal\n",
      "\n",
      "                      Pred       \n",
      "                Non Normal Normal\n",
      "True Non Normal         10      5\n",
      "     Normal              4    131\n",
      "F1-Score for class Normal : 0.967\n",
      "-----------------------------------\n",
      "\n",
      "#-- Confusion Matrix for class Abnormal\n",
      "\n",
      "                          Pred         \n",
      "                  Non Abnormal Abnormal\n",
      "True Non Abnormal          131        4\n",
      "     Abnormal                5       10\n",
      "F1-Score for class Abnormal : 0.690\n",
      "-----------------------------------\n",
      "\n",
      "#-- Final Macro F1-Score\n",
      "( 0.967 + 0.690 ) / 2 = 0.8282\n"
     ]
    }
   ],
   "source": [
    "result=explain.ShowResult(true_total_label, pred_total_label)\n",
    "result.show_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
